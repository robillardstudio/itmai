# Images trompeuses et modèles d'intelligence artificielle

Cycle journée d'étude et ateliers, les 12 et 13 octobre 2023 au Fresnoy, Studio national des arts contemporains

___Misleading Images and Artificial Intelligence Models___

_Study day and workshops, October 12 and 13 at Fresnoy, National studio of contemporary arts_

<!-- ----

Organisation Gaëtan Robillard et Renée Bourassa, groupe de recherche international Arcanes CRILCQ, Université Laval (Canada)  -->

![affiche](medias/cover.jpg)

[Voir programme en pdf (_see program as pdf_)](medias/programme.pdf)

<!-- [Voir demo atelier Machine Unlearning (*see demo for Machine Unlearning workshop*)]() -->

## Résumés (_Abstracts_)

### 12 Octobre. Journée d'étude (_Study day_)

#### Kazushi Mukaiyama, Université du futur Hakodate [en ligne]

"Mes lignes tracées par l'IA"

Dans le domaine de l’image, l’IA générative suscite aujourd’hui beaucoup d’attention. Depuis plus de vingt ans, Kazushi Mukaiyama développe un programme de peinture par IA car il cherchait à savoir pourquoi les humains produisent ou s’intéressent à l’art. Durant cette période, Shizuka – le peintre IA, a connu plusieurs changements. Tout d’abord, il ne pouvait dessiner qu’une seule image fixe à la fois, telle une scène. Ensuite, des tentatives ont été faites pour créer des séquences d’images continues à la manière d’un manga, telles des histoires. Dernièrement, le programme a dessiné des images à partir de lignes produites par Mukaiyama lui-même. Ce résultat lui permet désormais d'envisager son propre processus créatif d'une manière entièrement inédite. Ainsi, l’IA fournit des indices lui permettant de comprendre ce qui fonde la capacité des humains à créer de l’art. L’une de ces indications est que, parmi toutes les créatures sur terre, seuls les humains peuvent tracer du texte. Et cette possibilité semble être intimement liée à notre capacité de traiter de l’art. Mukaiyama a pu le vérifier en utilisant l'IA générative d’aujourd’hui appliquée aux images. En outre, la présentation abordera des points importants pour réfléchir à l’avenir de ce domaine de recherche.

*"My lines drawn by AI"*

*Image-generative AI is getting a lot of attention right now. Kazushi Mukaiyama has been developing an AI painting program for over 20 years because he wanted to know why humans make or deal with art. During this time, Shizuka, the AI painter, has undergone various changes. First of all, it could only draw one still picture at a time, like a scene. Then, attempts were made to create continuous Manga-like sequences of images, like stories. Lately, the program drew images from lines directly produced by Mukaiyama. This result is now enabling him to consider his creative process in a deep novel way. Thus, AI is giving him hints to understand the way humans can make art. One of the hints is that, of all the creatures on earth, only humans can draw text. And this ability seems to be deeply related to our ability to deal with art. Mukaiyama has been able to verify this by using the current image-generative AI which he will talk about. In addition, the presentation will discuss what is needed for thinking about the future of image-generative AI.*

#### Terence Broad, University of the Arts London

"Intrusions astucieuses : Guide du hacker sur l'IA générative"

Les modèles d’IA générative, bien que capables de produire des images convaincantes, occultent souvent leurs processus créatifs. Ils fournissent une forme illusoire de production médiatique, dans laquelle les mécanismes de formation sont obscurcis par des processus de boîte noire. Cette conférence présentera trois projets artistiques : Being Foiled, Teratome et Ghosts, tous nés d'une approche hacker de l'IA générative. Ces travaux sont le résultat de différentes interventions dans les phases d’entraînement et de génération de modèles d’IA, chacune offrant un aperçu unique du fonctionnement des processus génératifs à l’oeuvre.

*"Artful Intrusions—A Hacker's Guide to Generative AI"*

*Generative AI models, while capable of producing convincing images, often obscure their creative processes. They provide an illusory form of media production, where the mechanics of formation are obscured by black-box processes. This talk will introduce three artistic projects—Being Foiled, Teratome, and Ghosts—all born from a hacker's approach to generative AI. These works were the result of different interventions into the training and generation phases of AI models, each offering unique insights into the workings of generative processes.*

#### Vincent Nozick, Université Gustave Eiffel, Paris

"Mesonet : Détecter la falsification de vidéos deepfakes"

L'apparition des deepfakes en 2017 a marqué un tournant dans le rapport que nous entretenons avec les vidéos truquées. Cette technique consiste à remplacer, sur un média vidéo, le visage d’une personne par celui d’une autre personne, en transférant les mouvements du visage ainsi que ses intentions. Cette technologie, et beaucoup d'autres depuis, permet de réaliser de fausses vidéos convaincantes en délégant les compétences de graphiste à la machine. Durant cette présentation, je propose de commencer par une description du fonctionnement des deepfakes, en particulier du détournement très élégant des modèles auto-encodeurs. Ensuite, je dresserai un panorama des approches de détection de deepfakes, notamment à l'aide de méthodes d'apprentissage profond. Nous pourrons évoquer la question du jeu du chat et de la souris, à savoir qui aura le dernier mot ? Enfin, je suggère de porter une réflexion sur l'usage du deep learning en sciences. Il se trouve que la détection des deepfakes correspond précisément à la période où les méthodes de détection de falsification d'images ont basculé de l'usage des mathématiques et du traitement du signal vers les méthodes d’apprentissage automatique.

*"Mesonet: Detecting deepfake video falsification"*

*The emergence of deepfakes in 2017 marked a turning point in our relationship with fake videos. This technique consists of replacing, on video media, the face of a person with that of another person, by transferring the facial movements as well as their intentions. This technology, and many others since, makes it possible to produce convincing fake videos by delegating graphic designer skills to the machine. During this presentation, I propose to start with a description of how deepfakes operate, in particular the very elegant appropriation of auto-encoder models. We can discuss the question of the cat and mouse game, namely who will have the last word? Finally, I suggest thinking about the use of deep learning in science. It turns out that deepfake detection corresponds precisely to the period when image forgery detection methods shifted from the use of mathematics and signal processing to machine learning methods.*

#### Nicolas Obin, IRCAM Centre Pompidou, Paris

"Deepfakes ou synthèse vocale"

La présentation portera sur les deepfakes dans le domaine sonore, et sur des problématiques en lien avec les domaines du journalisme et des médias. Mais la synthèse vocale est aussi un sujet plus large qui irrigue de nombreuses pratiques créatives. La présentation ouvrira donc sur des projets élaborés en collaboration avec des artistes, cinéastes ou compositeurs.

*"Deepfakes or Speech Synthesis"*

*The presentation will focus on deepfakes in the audio field, and on issues related to the fields of journalism and media. But speech synthesis is also a broader subject, and nourishes many creative practices. The presentation will therefore open to projects developed in collaboration with artists, filmmakers or composers.*

#### Constantine Boussalis, Trinity College, Dublin

"Le tournant informatique dans la recherche sur la communication politique visuelle"

À une époque saturée de données visuelles, les techniques computationnelles sont devenues indispensables pour déchiffrer la communication politique et la désinformation à grande échelle. Cet exposé propose une revue concise de l’application de la vision par ordinateur dans la recherche contemporaine en communication politique visuelle. En tirant parti des outils d’apprentissage automatique, les chercheurs ont non seulement ouvert de nouvelles voies d’enquête sur divers sujets, allant des manifestations politiques à la propagande extrémiste, mais se sont également aventurés dans le domaine de la génération texte-image pour étudier le comportement politique. À mesure que ces techniques prennent de l’ampleur, les biais potentiels et les dimensions éthiques de la représentation des ensembles de données et des modèles génératifs deviennent encore plus évidents. Cette présentation vise à offrir un aperçu succinct du paysage actuel des méthodes computationnelle dans la recherche politique visuelle, abordant à la fois leurs capacités sans précédent et leurs défis inhérents.

*"The Computational Turn in Visual Political Communication Research"*

*In an era saturated with visual data, computational techniques have become invaluable for deciphering political communication and misinformation at large scales. This talk provides a concise review of the application of computer vision in contemporary visual political communication research. Leveraging machine learning tools, researchers have not only opened new avenues of inquiry into diverse topics, from political protests to extremist propaganda, but also ventured into the realm of text-to-image generation to study political behavior. As these techniques gain momentum, the potential biases and ethical dimensions of dataset representation and generative models become even more salient. This presentation aims to offer a succinct overview of the current landscape of computational methods in visual political research, addressing both their groundbreaking capabilities and inherent challenges.*

#### Fabien Richert, Université du Québec à Montréal [en ligne]

"Converser avec l’IA : entre feintise ludique et stratégie de tromperie"

Dans cette communication, nous présenterons les premiers résultats d’un projet de recherche mené actuellement au sein du Laboratoire de recherche en médias socionumériques et ludification (UQAM) et au cours duquel nous analysons les assistants virtuels intelligents (notamment Google Home, Alexa, Siri et ChatGPT) comme des dispositifs qui permettent à leurs concepteurs·rices d’interpeller, de manière plus ou moins directe, les personnes qui utilisent ces outils numériques. Plus que de simples logiciels informatiques, ces dispositifs sont capables de mobiliser simultanément plusieurs systèmes de signes (visuels, langagiers, sonores, etc.), de simuler des émotions et des sentiments ou encore de se livrer à des performances diverses et variées (écrire un poème, chanter, jouer le rôle de personnages célèbres, etc.). À partir d’exemples issus de notre recherche, nous nous intéresserons aux stratégies de « feintise ludique » (Schaeffer, 1999) que déploient ces dispositifs pour donner l’impression que leurs utilisateurs et utilisatrices conversent avec des personnages vivants et autonomes, animés par une conscience et des désirs qui leur sont propres. Nous nous interrogerons alors sur les enjeux posés par de telles stratégies pouvant dériver vers des situations où les personnes ne parviennent plus à distinguer le vrai du faux, l’humain de la machine.

*"Conversing with AI: between playful feinting and deception strategy"*

*In this communication, we will present the first results of a research project currently carried out within the Research Laboratory in Socio-Digital Media and Gamification (UQAM) and during which we analyze intelligent virtual assistants (notably Google Home, Alexa, Siri and ChatGPT) as devices that allow their designers to engage, in a more or less direct way, with people who use these digital tools. More than just computer software, these devices are capable of simultaneously mobilizing several sign systems (visual, language, sound, etc.), of simulating emotions and feelings or even of engaging in diverse and varied performances (writing a poem, sing, play the role of famous characters, etc.). Using examples from our research, we will focus on the “playful feint” strategies (Schaeffer, 1999) that these devices deploy to give the impression that their users are conversing with living and autonomous characters, animated by a consciousness and desires of their own. We will then question the issues posed by such strategies which can lead to situations where people are no longer able to distinguish truth from falsehood, human from machine.*

#### Olga Kisseleva, Institut International Art&Science, Paris

"De l’intelligence en essaim à l’intelligence artificielle, et vice versa"

La présentation d’Olga Kisseleva sera basée sur une longue expérience des rapports entre Intelligence Artificielle et art, ainsi que sur son implication récente avec l'Observatoire de l'Intelligence artificielle de Paris 1 Panthéon-Sorbonne et au sein du projet CulturIA du CNRS. Dans le cadre de cette thématique, elle abordera : -  La notion d'intelligence : qu'est-ce qui différencie l'intelligence naturelle de l'IA.  Est-il approprié, dans les deux cas, de parler d’intelligence ? Peut-on les placer sur un même plan ? - Le rôle de l'art comme médiateur entre des domaines, et qui permet de déployer et inventer de nouveaux objets, de nouveaux langages à l’aide de différentes formes de l'intelligence. - La manière dont l'intelligence naturelle peut améliorer l'IA ; comment, à l'inverse, l'IA peut-elle contribuer à réparer notre monde, dans une perspective écologique ? - Le danger de la récupération, par le capitalisme de certaines recherches biotechnologiques et ma démarche d’artiste comme une manière de détourner l’IA, de proposer d'autres formes de réseaux, de connexions que celles auxquelles nous pensons généralement. - L'intelligence naturelle comme un modèle alternatif à l’IA.

*"From swarm intelligence to artificial intelligence, and back again"*

*Olga Kisseleva's presentation will be based on extensive experience in the relationship between Artificial Intelligence and art, as well as her recent involvement with the Observatory of Artificial Intelligence of Paris 1 Panthéon-Sorbonne and within the CNRS CulturIA project. Within the framework of this theme, she will address: - The notion of intelligence: what differentiates natural intelligence from AI. Is it appropriate to speak of intelligence in both cases? Are they comparable? - The role of art as a mediator between domains, allowing the deployment and invention of new objects, and new languages using different forms of intelligence. - How natural intelligence can improve AI; how, conversely, can AI help repair our world, from an ecological perspective? - The danger of exploitation, by capitalism, of certain biotechnological research and my artistic approach as a way of hijacking AI, of proposing other forms of networks, of connections than those we generally think of. - Natural intelligence as an alternative model to AI.*

#### Frank Madlener, IRCAM Centre Pompidou

"Après l’intelligence artificielle : l’éthique, les tics et l’esthétique"

Sur la scène culturelle, médiatique et fantasmatique, l’Intelligence Artificielle et l’Ingénierie Ambiante occupent une place grandissante. Au moment où elles semblent défier la créativité humaine, on leur accorde toutes les vertus et tous les maléfices, par un effet de symétrie entre messianisme et catastrophisme. Les apôtres de la désinhibition technologique, tout comme les éreinteurs du présent, offrent trop peu de prise sur la manière d’habiter, d’inventer, de hanter un monde possible. Dans cette contribution à la journée d’étude du Fresnoy, il sera question d’apprentissage machine et de désapprentissage humain, de la conversion d’un médium dans l’autre et de l’intraductible, du possible et de l’improbable.

*"After artificial intelligence: ethics, mannerisms and aesthetics"*

*In the worlds of culture, media and fantasy, artificial intelligence and ambient innovation are playing an increasingly prominent role. When they seem to challenge human creativity, they are credited with all the virtues and all the evils, in an almost perfect symmetry between messianism and
catastrophism. The apostles of technological disinhibition, like the tense critics of our age, offer too little insight into the way of inhabiting, inventing, or haunting a possible world. In this contribution to the Fresnoy study day, it will be about machine learning and human unlearning, the conversion of one medium into another and the untranslatable, the possible and the improbable.*


### 13 Octobre. Ateliers (_Workshops_)

Les ateliers son premièrement destinés aux étudiants du Fresnoy.

*Workshops are primarely aimed at Fresnoy students.*


#### Gaëtan Robillard, Université Laval, Québec

"Machine Unlearning"

Nous nous intéresserons ici au modèle MobileNET, un réseau d’apprentissage profond entraîné pour la classification d’images. Il s’agira d’interagir avec ce modèle à travers un programme JavaScript de quelques lignes (librairies p5.js et ml5.js). Grâce à des input graphiques et aléatoires, nous chercherons à déjouer la reconnaissance d’image pour ensuite explorer les biais d’entraînement du modèle.

"GANs et usage de faux"

Nous nous appuierons sur un environnement de travail spécialement conçu pour la recherche sur les réseaux adversaires génératifs (GAN). Cet environnement est pensé pour quiconque souhaiterait découvrir, façonner ou critiquer ce type de modèle, en particulier dans un contexte de recherche et d’expérimentation visuelle. Nous explorerons des jeux de données et nous verrons comment produire des images en mouvement. L’atelier ouvrira sur la présentation de prompts pour la génération vidéo.

*"Machine Unlearning"*

*We will focus here on the MobileNET model, a deep learning network trained for image classification. This will involve interacting with this model through a JavaScript program made of a few lines of code (p5.js and ml5.js libraries). Using random graphic input, we will seek to contradict image recognition and then explore the model’s training biases.*

*"GANs and other forgeries"*

*We will rely on a work environment specially designed for research on generative adversarial networks (GAN). This environment is designed for anyone who would like to discover, shape or criticize this type of model, particularly in a context of research and visual experimentation. We will explore datasets and see how to produce moving images. The workshop will open with the presentation of prompts for video generation.*

#### Alain Lioret, Université Paris 8 [en ligne]

"L’Art Génératif Quantique"

On verra comment utiliser l’informatique quantique pour la générativité artistique et comment les techniques avancées d’intelligence artificielle ouvrent-elles de nouvelles perspectives avec les algorithmes quantiques. On découvrira comment les principes de superposition, d’intrication, de téléportation quantiques peuvent apporter des outils nouveaux pour les artistes.

*"Quantum Generative Art"*

*We will see how to use quantum computing for artistic generativity and how advanced artificial intelligence techniques open up new prospects with quantum algorithms. We will discover how the principles of quantum superposition, entanglement and teleportation can provide new tools for artists.*

## Biographies

### Constantine Boussalis

Constantine Boussalis est maître de conférences en sciences politiques au Trinity College de Dublin. Ses recherches se situent à l’intersection des sciences politiques et des méthodes computationnelle, avec un accent particulier sur la désinformation dans la communication sur le changement climatique ainsi que sur la communication politique par l’émotion et le non verbal.

*Constantine Boussalis is an Associate Professor in Political Science at Trinity College Dublin. His research lies at the intersection of political science and computational methods, with a prominent focus on misinformation in climate change communication as well as emotive and non-verbal political communication.*

### Terence Broad

Terence Broad est un artiste et chercheur basé à Londres. Il est maître de conférences à l'Université des Arts de Londres (UAL), attaché au Creative Computing Institute. Son art et ses recherches ont été présentés à l'échelle internationale : dans des conférences et des revues telles que SIGGRAPH, Leonardo, NeurIPS, EvoMUSART et ICCC ; et des musées tels que le Whitney Museum of American Art, le Garage Museum of Contemporary Art, Ars Electronica, The Barbican et The Whitechapel Gallery. En 2019, il a remporté le Grand Prix de la galerie d'art ICCV Computer Vision et a régulièrement fait partie du jury de SIGGRAPH. Son travail fait partie de la collection d’art contemporain de la ville de Genève.

*Terence Broad is an artist and researcher working in London. He is a Senior Lecturer at the UAL Creative Computing Institute. His art and research have been presented internationally: at conferences and journals such as SIGGRAPH, Leonardo, NeurIPS, EvoMUSART, and ICCC; and museums such as The Whitney Museum of American Art, Garage Museum of Contemporary Art, Ars Electronica, The Barbican and The Whitechapel Gallery. In 2019 He won the Grand Prize in the ICCV Computer Vision Art Gallery and has regularly served on the Jury for SIGGRAPH. His work is in the city of Geneva’s contemporary art collection.*

### Olga Kisseleva

Mathématicienne à l’origine, artiste est fondatrice du laboratoire Art&Science de la Sorbonne, Olga Kisseleva ne découvre pas l’IA en 2022. Elle l’explore depuis le début des années 2000, avec ses œuvres comme Power Struggle (2011) et EDEN (2012-présent), entre autres. Ses œuvres traitent notamment des liens entre l’IA et l’intelligence de la nature comme son récent projet AntiCorps (2020-2021), et la toute nouvelle série Cities Live Like Trees (2022).

*Originally a mathematician, artist and founder of the Art&Science laboratory at the Sorbonne, Olga Kisseleva did not discover AI in 2022. She has been exploring it since the early 2000s, with her works such as Power Struggle (2011) and EDEN ( 2012-present), among others. her works notably deal with the links between AI and the intelligence of nature such as her recent project AntiCorps (2020-2021), and the brand new series Cities Live Like Trees (2022).*

### Alain Lioret

Alain Lioret est Professeur en Arts et Technologies de l'Image à l'Université Paris 8. Il enseigne la programmation 3D et les techniques de génération procédurale. Spécialiste de l'Art Génératif, ses domaines de recherche se situent aux frontières de l'Art et de l'Intelligence Artificielle. Il travaille depuis une dizaine d'années sur les perspectives artistiques que peuvent apporter l'informatique quantique.

*Alain Lioret is Professor of Image Arts and Technologies at the University of Paris 8. He teaches 3D programming and procedural generation techniques. Specialist in Generative Art, his areas of research lie at the frontiers of Art and Artificial Intelligence. He has been working for around ten years on the artistic perspectives that quantum computing can bring.*

### Frank Madlener

Frank Madlener est le directeur de l’Ircam-Centre Pompidou et de ManiFeste, le Festival du Printemps à Paris depuis 2012. Musicien, formé au piano, à l’histoire de la musique et à la direction d’orchestre en France et en Autriche, il a aussi étudié la philosophie des sciences et l’esthétique. En 2019, il fonde Ircam Amplify, entreprise technologique qui porte la révolution de l’audio dans les industries culturelles et créatives. L’Ircam, institut de recherche et coordination acoustique/musique est aujourd’hui l’un des plus grands centres de recherche publique au monde se consacrant à la création musicale et à la recherche scientifique. Lieu unique où convergent la prospective artistique et l’innovation scientifique et technologique, l’institut réunit plus de cent soixante collaborateurs.

*Frank Madlener is the director of the IRCAM-Centre Pompidou and ManiFeste, the Spring Festival in Paris since 2012. Musician, trained in piano, music history and conducting in France and Austria , he also studied philosophy of science and aesthetics. In 2019, he founded Ircam Amplify, a technology company driving the audio revolution in the cultural and creative industries. IRCAM, Institute for Research and Coordination in Acoustics/Music, is today one of the largest public research centers in the world dedicated to musical creation and scientific research. As a unique place where artistic foresight and scientific and technological innovation converge, the institute brings together more than one hundred and sixty collaborators.*

### Kazushi Mukaiyama

Kazushi Mukaiyama est le créateur de Shizuka, le peintre IA et professeur au Département d'architecture des médias de la Future University Hakodate. Il a obtenu une maîtrise des Beaux-Arts en 1993, à l'Université des Arts de la ville de Kyoto, où Il a ensuite obtenu son doctorat en arts médiatiques en 2004. Son intérêt de recherche est le traitement de l’information dans la création artistique. Il a remporté le prix de la catégorie .net du Prix Ars Electronica 2000 (Linz). Il a également été sélectionné pour FILE 2011 (Sao Paulo) et a remporté le prix d'encouragement du concours de bande dessinée au concours public Ikebukuro Art Gathering 2022 (Tokyo).

*Kazushi Mukaiyama is the maker of Shizuka, the AI painter, and a Professor of the Department of Media Architecture at Future University Hakodate. He received a M.A. in Fine Art in 1993 from Kyoto City University of Arts, where he then was awarded his Ph.D, in Media Art, in 2004. His research interest lies in the information processing of art creations. He won a prize in the .net category at Prix Ars Electronica 2000 (Linz). He also was selected for FILE 2011 (Sao Paulo), and won the Encouragement Prize in the Comic Competition at the 2022 Ikebukuro Art Gathering public competition (Tokyo).*

### Vincent Nozick

Vincent Nozick est maître de conférences à l’Université Gustave Eiffel, au sein du laboratoire d’informatique Gaspard Monge. Ses domaines de recherche couvrent la vision par ordinateur, la détection de falsifications d’images et les algèbres géométriques. Il a effectué une partie de sa carrière au Japon, à l’université de Keio de 2006 à 2008 puis dans une délégation CNRS au Laboratoire Franco-Japonnais pour l’Informatique (JFLI) de 2016 à 2018. Il dirige actuellement la formation Esiee-Imac, liant arts et sciences dans le domaine de l’image.

*Vincent Nozick is a lecturer at Gustave Eiffel University, in the Gaspard Monge computer science laboratory. His research interests cover computer vision, image forgery detection and geometric algebra. He spent part of his career in Japan, at Keio University from 2006 to 2008 then in the framework of CNRS delegation, in the Japanese-French Laboratory for Informatics, from 2016 to 2018. He currently directs the Esiee-Imac training program, linking arts and sciences in regards to image.*

### Nicolas Obin

Nicolas Obin est maître de conférences à la Faculté des sciences et d'ingénierie de Sorbonne Université et chercheur dans l'équipe analyse et synthèse des sons du laboratoire Sciences et Technologies de la Musique et du Son (Ircam, CNRS, Sorbonne Université). En 2011 il obtient le prix de la meilleure thèse de doctorat de La Fondation Des Treilles. Ses activités de recherche couvrent le traitement du signal audio, l'intelligence artificielle, et la modélisation statistique des signaux sonores, avec une spécialisation sur le traitement de la parole et de la communication humaine. Son principal domaine de recherche est la modélisation générative structurée de productions humaines complexes telles que la parole, le chant et la musique, avec diverses applications dans la synthèse et la transformation de la parole, l'animation d'agents virtuels multimodaux, la robotique humanoïde, et les deepfakes. Son engagement artistique avec l'Ircam l'amène à contribuer à de nombreux projets avec musiciens et artistes.

*Nicolas Obin is a lecturer at the Faculty of Science and Engineering at Sorbonne University and a researcher in the sound analysis and synthesis team at the Science and Technology of Music and Sound laboratory (Ircam, CNRS, Sorbonne University). In 2011 he won the prize for the best doctoral thesis from La Fondation Des Treilles. His research activities cover audio signal processing, artificial intelligence, and statistical modeling of sound signals, with a specialization on speech processing and human communication. His main area of research is the structured generative modeling of complex human productions such as speech, singing and music, with various applications in speech synthesis and transformation, animation of multimodal virtual agents, humanoid robotics and deepfakes. His artistic commitment to IRCAM leads him to contribute to numerous projects with musicians and artists.*

### Fabien Richert

Fabien Richert est docteur en sémiologie et professeur à l'École des médias de l'Université du Québec à Montréal (UQAM). Il est aussi chercheur associé au CRICIS (Centre de recherche interuniversitaire sur la communication, l'information et la société), au CRILCQ (Centre de recherche interuniversitaire sur la littérature et la culture au Québec), co-chercheurs dans le projet de recherche CRSH «  Des arts trompeurs à la post-vérité : régimes d’authenticité en contexte numérique »  et codirecteur du GRISQ (Groupe de recherche sur l'information et la surveillance au quotidien). Fabien Richert s'intéresse actuellement aux logiques qui sous tendent le développement d'une rationalité algorithmique à l'œuvre dans une multitude d'objets médiatiques contemporains (applications, médias sociaux, jeux vidéo, IA, etc.).

*Fabien Richert is a doctor in semiology and professor at the Media School of the University of Quebec in Montreal (UQAM). He is also Associate researcher at CRICIS (Interuniversity Research Center on Communication, Information and Society), at CRILCQ (Interuniversity Research Center on Literature and Culture in Quebec), co-researcher in the CRSH research project “From the deceptive arts to post-truth: regimes of authenticity in a digital context”, and co-director of GRISQ (Research Group on Information and everyday surveillance). Fabien Richert is currently interested in logics which underlie the development of an algorithmic rationality at work in a multitude of contemporary media objects (applications, social media, video games, AI, etc.).*

### Gaëtan Robillard

Gaëtan Robillard (FR) est artiste et chercheur, actuellement post doctorant à l’Université Laval (CA), vivant et travaillant entre le Grand Paris et Montréal. Il produit un ensemble d’installations utilisant datas et médias, engagées dans la recherche en mathématique, la climatologie et les sciences cognitives. Son travail a été exposé dans des lieux tels que le Palais de Tokyo et l’Ircam Centre Pompidou (Paris), Akbank Sanat (Istanbul) et le ZKM Centre d’art et de technologie des médias (Karlsruhe). Il publie régulièrement des articles sur l’esthétique du Computer Art historique, l’éducation et les artefacts algorithmiques contemporains.

*Gaëtan Robillard (FR) is an artist and a researcher, currently a postdoctoral fellow at Laval University (CA), living and working between the Greater Paris and Montreal. He produces data art and media based installations engaging with mathematical research, climatology and cognitive sciences. His work has been exhibited in venues such as Palais de Tokyo and Ircam Centre Pompidou (Paris), Pearl Art Museum (Shanghai), Akbank Sanat (Istanbul), and ZKM Center for Art and Media (Karlsruhe). In 2022, he obtained a PhD in art and technology from the University of Paris 8, and published several texts on early computer art aesthetics, education and contemporary algorithmic artifacts.*

## Ressources ateliers (_Workshops material_)

![machine unlearning](machine-unlearning/image.gif)

Gaëtan Robillard, Machine Unlearning : see [machine-unlearning](/machine-unlearning) folder for JavaScript exemple.

Machine Unlearning exemple in p5 web editor : [https://editor.p5js.org/gaetan/sketches/dPT8z1TKO](https://editor.p5js.org/gaetan/sketches/dPT8z1TKO)

Ml5 : Friendly Machine Learning for the Web : [https://ml5js.org](https://ml5js.org/)

Gaëtan Robillard, Trois lignes dans un espace latent (Three Lines in a Latent Space) : [https://github.com/robillardstudio/three-lines-in-latent-space](https://github.com/robillardstudio/three-lines-in-latent-space)

**Ressources complémentaires (Further ressources)**

References for Stable diffusion webui colab [https://github.com/camenduru/stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab)

Stable Diffusion web UI by AUTOMATIC 1111 [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
